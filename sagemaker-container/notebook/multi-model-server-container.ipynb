{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Multi Model Server Container for Differential Deep Learning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build and use a custom Docker container for serving with Amazon SageMaker that leverages on the <strong>Multi Model Server (MMS)</strong> and <strong>sagemaker-inference-toolkit</strong> libraries for serving models through Amazon SageMaker's endpoints.\n",
    "We will also see how MMS allows deploying multiple models on a single endpoint thanks to the multi-model endpoints functionality of Amazon SageMaker Hosting (https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html).\n",
    "\n",
    "Useful links:\n",
    "- https://github.com/awslabs/multi-model-server/\n",
    "- https://github.com/aws/sagemaker-inference-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785577973223\n",
      "us-east-1\n",
      "arn:aws:iam::785577973223:role/admin\n",
      "sagemaker-us-east-1-785577973223\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-serving-containers/'\n",
    "prefix = 'diffdl-container'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the Dockerfile which defines the statements for building our serving container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33mtensorflow/tensorflow:latest\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mLABEL\u001b[39;49;00m \u001b[31mmaintainer\u001b[39;49;00m=\u001b[33m\"Oleg Grytsynevych\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Set a docker label to advertise multi-model support on the container\u001b[39;49;00m\r\n",
      "\u001b[34mLABEL\u001b[39;49;00m com.amazonaws.sagemaker.capabilities.multi-models=true\r\n",
      "\u001b[37m# Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present\u001b[39;49;00m\r\n",
      "\u001b[34mLABEL\u001b[39;49;00m com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\r\n",
      "\r\n",
      "\u001b[37m# Install python and other runtime dependencies\u001b[39;49;00m\r\n",
      "\u001b[34mRUN\u001b[39;49;00m apt-get update && \u001b[33m\\\u001b[39;49;00m\r\n",
      "    apt-get -y install \u001b[33m\\\u001b[39;49;00m\r\n",
      "        build-essential \u001b[33m\\\u001b[39;49;00m\r\n",
      "        libatlas-dev \u001b[33m\\\u001b[39;49;00m\r\n",
      "        git \u001b[33m\\\u001b[39;49;00m\r\n",
      "        wget \u001b[33m\\\u001b[39;49;00m\r\n",
      "        curl \u001b[33m\\\u001b[39;49;00m\r\n",
      "        openjdk-8-jdk-headless\r\n",
      "\r\n",
      "\u001b[37m# Python wonâ€™t try to write .pyc or .pyo files on the import of source modules\u001b[39;49;00m\r\n",
      "\u001b[37m# Force stdin, stdout and stderr to be totally unbuffered. Good for logging\u001b[39;49;00m\r\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONDONTWRITEBYTECODE\u001b[39;49;00m=\u001b[34m1\u001b[39;49;00m \u001b[31mPYTHONUNBUFFERED\u001b[39;49;00m=\u001b[34m1\u001b[39;49;00m \u001b[31mPYTHONIOENCODING\u001b[39;49;00m=UTF-8 \u001b[31mLANG\u001b[39;49;00m=C.UTF-8 \u001b[31mLC_ALL\u001b[39;49;00m=C.UTF-8\r\n",
      "\r\n",
      "\u001b[37m# Install MMS, and SageMaker Inference Toolkit to set up MMS\u001b[39;49;00m\r\n",
      "\u001b[34mRUN\u001b[39;49;00m pip --no-cache-dir install multi-model-server \u001b[33m\\\u001b[39;49;00m\r\n",
      "                               sagemaker-inference \u001b[33m\\\u001b[39;49;00m\r\n",
      "                               retrying\r\n",
      "                                \r\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mCOPY\u001b[39;49;00m code/multi_model_serving-1.0.0.tar.gz /multi_model_serving-1.0.0.tar.gz\r\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install /multi_model_serving-1.0.0.tar.gz && rm /multi_model_serving-1.0.0.tar.gz\r\n",
      "\r\n",
      "\u001b[34mCOPY\u001b[39;49;00m code/serve.py /serve.py\r\n",
      "\u001b[34mENTRYPOINT\u001b[39;49;00m [\u001b[33m\"python\"\u001b[39;49;00m, \u001b[33m\"serve.py\"\u001b[39;49;00m]\r\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At high-level the Dockerfile specifies the following operations for building this container:\n",
    "\n",
    "- Set two Docker labels to advertise multi-model support and to enable the container using the SAGEMAKER_BIND_TO_PORT environment variable, if present\n",
    "- Install libraries (including OpenJDK since MMS frontend is Java-based) and Python 3.6 through miniconda\n",
    "- Set e few environment variables, including PYTHONUNBUFFERED which is used to avoid buffering Python standard output (useful for logging)\n",
    "- Install XGBoost (it is the ML framework of choice for this example)\n",
    "- Install Multi Model Server (MMS) and SageMaker Inference Toolkit\n",
    "- Copy a .tar.gz package named <strong>multi_model_serving-1.0.0.tar.gz</strong> in the WORKDIR\n",
    "- Install this package\n",
    "- Copy the serve.py file in the WORKDIR and use it as the Docker ENTRYPOINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the content of the <strong>serve.py</strong> file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m CalledProcessError\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mretrying\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m retry\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmulti_model_serving\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m handler_service\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_inference\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m model_server\r\n",
      "\r\n",
      "HANDLER_SERVICE = handler_service.\u001b[31m__name__\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_retry_if_error\u001b[39;49;00m(exception):\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(exception, CalledProcessError)\r\n",
      "\r\n",
      "\u001b[90m@retry\u001b[39;49;00m(stop_max_delay=\u001b[34m1000\u001b[39;49;00m * \u001b[34m30\u001b[39;49;00m,\r\n",
      "       retry_on_exception=_retry_if_error)\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_start_model_server\u001b[39;49;00m():\r\n",
      "    \u001b[37m# there's a race condition that causes the model server command to\u001b[39;49;00m\r\n",
      "    \u001b[37m# sometimes fail with 'bad address'. more investigation needed\u001b[39;49;00m\r\n",
      "    \u001b[37m# retry starting mms until it's ready\u001b[39;49;00m\r\n",
      "    model_server.start_model_server(handler_service=HANDLER_SERVICE)\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    _start_model_server()\r\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../docker/code/serve.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Handler Service</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the Dockerfile above, you might be askiong yourself what the <strong>multi_model_serving-1.0.0.tar.gz</strong> package is.\n",
    "When building a framework container for serving, sagemaker-inference-toolkit allows you to pass an handler service that will define the default inference handling logic, when users do not pass any custom inference script. The package above contains this code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the content of the handler service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_inference\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdefault_handler_service\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DefaultHandlerService\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_inference\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtransformer\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Transformer\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmulti_model_serving\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdefault_inference_handler\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DefaultDiffDLInferenceHandler\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\r\n",
      "\r\n",
      "ENABLE_MULTI_MODEL = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mSAGEMAKER_MULTI_MODEL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mfalse\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) == \u001b[33m\"\u001b[39;49;00m\u001b[33mtrue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mHandlerService\u001b[39;49;00m(DefaultHandlerService):\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "        \u001b[36mself\u001b[39;49;00m._initialized = \u001b[34mFalse\u001b[39;49;00m\r\n",
      "        \r\n",
      "        transformer = Transformer(default_inference_handler=DefaultDiffDLInferenceHandler())\r\n",
      "        \u001b[36msuper\u001b[39;49;00m(HandlerService, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m(transformer=transformer)\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32minitialize\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, context):\r\n",
      "        \u001b[37m# This code is a workaround to fix a bug in the inference toolkit not setting the\u001b[39;49;00m\r\n",
      "        \u001b[37m# user module path correctly when multi-model is enabled.\u001b[39;49;00m\r\n",
      "        \u001b[37m# To be removed when the toolkit fix is available.\u001b[39;49;00m\r\n",
      "        \u001b[34mif\u001b[39;49;00m (\u001b[35mnot\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._initialized) \u001b[35mand\u001b[39;49;00m ENABLE_MULTI_MODEL:\r\n",
      "            code_dir = context.system_properties.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) + \u001b[33m'\u001b[39;49;00m\u001b[33m/code\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            sys.path.append(code_dir)\r\n",
      "            \u001b[36mself\u001b[39;49;00m._initialized = \u001b[34mTrue\u001b[39;49;00m\r\n",
      "        \r\n",
      "        \u001b[37m# Printing system properties for debugging purposes.\u001b[39;49;00m\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mContext system properties: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(context.system_properties)\r\n",
      "\r\n",
      "        \u001b[36msuper\u001b[39;49;00m().initialize(context)\r\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../package/src/multi_model_serving/handler_service.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the logic defined in the default inference handler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpkl\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_inference\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m content_types, decoder, default_inference_handler, encoder, errors\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmulti_model_serving\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m encoder \u001b[34mas\u001b[39;49;00m xgb_encoders\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mDefaultDiffDLInferenceHandler\u001b[39;49;00m(default_inference_handler.DefaultInferenceHandler):\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mdefault_input_fn\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_data, content_type):\r\n",
      "        \u001b[33m\"\"\"Take request data and de-serializes the data into an object for prediction.\u001b[39;49;00m\r\n",
      "\u001b[33m        When an InvokeEndpoint operation is made against an Endpoint running SageMaker model server,\u001b[39;49;00m\r\n",
      "\u001b[33m        the model server receives two pieces of information:\u001b[39;49;00m\r\n",
      "\u001b[33m            - The request Content-Type, for example \"application/json\"\u001b[39;49;00m\r\n",
      "\u001b[33m            - The request data, which is at most 5 MB (5 * 1024 * 1024 bytes) in size.\u001b[39;49;00m\r\n",
      "\u001b[33m        The input_fn is responsible to take the request data and pre-process it before prediction.\u001b[39;49;00m\r\n",
      "\u001b[33m        Args:\u001b[39;49;00m\r\n",
      "\u001b[33m            input_data (obj): the request data.\u001b[39;49;00m\r\n",
      "\u001b[33m            content_type (str): the request Content-Type.\u001b[39;49;00m\r\n",
      "\u001b[33m        Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m            (obj): data ready for prediction. For XGBoost, this defaults to DMatrix.\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[37m#return xgb_encoders.decode(input_data, content_type)\u001b[39;49;00m\r\n",
      "        \u001b[37m#TODO: use my own code\u001b[39;49;00m\r\n",
      "        \u001b[36mprint\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mDoing default_input_fn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mdefault_predict_fn\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, data, model):\r\n",
      "        \u001b[33m\"\"\"A default predict_fn for XGBooost Framework. Calls a model on data deserialized in input_fn.\u001b[39;49;00m\r\n",
      "\u001b[33m        Args:\u001b[39;49;00m\r\n",
      "\u001b[33m            input_data: input data (Numpy array) for prediction deserialized by input_fn\u001b[39;49;00m\r\n",
      "\u001b[33m            model: XGBoost model loaded in memory by model_fn\u001b[39;49;00m\r\n",
      "\u001b[33m        Returns: a prediction\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[37m#TODO: use my own code \u001b[39;49;00m\r\n",
      "        \u001b[37m# output = model.predict(data, validate_features=False)\u001b[39;49;00m\r\n",
      "        \u001b[36mprint\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mDoing default_predict_fn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "        output = \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m;\r\n",
      "        \r\n",
      "        \u001b[34mreturn\u001b[39;49;00m output\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mdefault_output_fn\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, prediction, accept):\r\n",
      "        \u001b[33m\"\"\"A default output_fn for XGBoost. Serializes predictions from predict_fn to JSON, CSV or NPY format.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m        Args:\u001b[39;49;00m\r\n",
      "\u001b[33m            prediction: a prediction result from predict_fn\u001b[39;49;00m\r\n",
      "\u001b[33m            accept: type which the output data needs to be serialized\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m        Returns: output data serialized\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[37m#return encoder.encode(prediction, accept)\u001b[39;49;00m\r\n",
      "            \u001b[37m#TODO: use my own code\u001b[39;49;00m\r\n",
      "        \u001b[36mprint\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mDoing default_output_fn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../package/src/multi_model_serving/default_inference_handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Build and push the container</h2>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/bin/sh\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[31mACCOUNT_ID\u001b[39;49;00m=\u001b[31m$1\u001b[39;49;00m\r\n",
      "\u001b[31mREGION\u001b[39;49;00m=\u001b[31m$2\u001b[39;49;00m\r\n",
      "\u001b[31mREPO_NAME\u001b[39;49;00m=\u001b[31m$3\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[36mcd\u001b[39;49;00m ../package/ || \u001b[36mexit\u001b[39;49;00m \u001b[34m1\u001b[39;49;00m\r\n",
      "python setup.py sdist || \u001b[36mexit\u001b[39;49;00m \u001b[34m1\u001b[39;49;00m\r\n",
      "cp dist/multi_model_serving-1.0.0.tar.gz ../docker/code/ || \u001b[36mexit\u001b[39;49;00m \u001b[34m1\u001b[39;49;00m\r\n",
      "\r\n",
      "docker build -f ../docker/Dockerfile -t \u001b[31m$REPO_NAME\u001b[39;49;00m ../docker\r\n",
      "\r\n",
      "docker tag \u001b[31m$REPO_NAME\u001b[39;49;00m \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\r\n",
      "\r\n",
      "\u001b[34m$(\u001b[39;49;00maws ecr get-login --no-include-email --registry-ids \u001b[31m$ACCOUNT_ID\u001b[39;49;00m\u001b[34m)\u001b[39;49;00m\r\n",
      "\r\n",
      "aws ecr describe-repositories --repository-names \u001b[31m$REPO_NAME\u001b[39;49;00m || aws ecr create-repository --repository-name \u001b[31m$REPO_NAME\u001b[39;49;00m\r\n",
      "\r\n",
      "docker push \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\r\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../scripts/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>--------------------------------------------------------------------------------------------------------------------</h3>\n",
    "\n",
    "The script builds the Docker container, then creates the repository if it does not exist, and finally pushes the container to the ECR repository. The build task requires a few minutes to be executed the first time, then Docker caches build outputs to be reused for the subsequent build operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plugins: extras_suggestions, langpacks, priorities, update-motd\n",
      "amzn2-core                                               | 3.7 kB     00:00     \n",
      "242 packages excluded due to repository priority protections\n",
      "Package docker-20.10.4-1.amzn2.x86_64 already installed and latest version\n",
      "Nothing to do\n"
     ]
    }
   ],
   "source": [
    "!sudo yum -y install docker\n",
    "!/opt/conda/bin/pip install docker-compose\n",
    "!/opt/conda/bin/pip install 'sagemaker[local]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing src/multi_model_serving.egg-info/PKG-INFO\n",
      "writing top-level names to src/multi_model_serving.egg-info/top_level.txt\n",
      "writing dependency_links to src/multi_model_serving.egg-info/dependency_links.txt\n",
      "reading manifest file 'src/multi_model_serving.egg-info/SOURCES.txt'\n",
      "writing manifest file 'src/multi_model_serving.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "creating multi_model_serving-1.0.0\n",
      "creating multi_model_serving-1.0.0/src\n",
      "creating multi_model_serving-1.0.0/src/multi_model_serving\n",
      "creating multi_model_serving-1.0.0/src/multi_model_serving.egg-info\n",
      "copying files to multi_model_serving-1.0.0...\n",
      "copying setup.py -> multi_model_serving-1.0.0\n",
      "copying src/multi_model_serving/__init__.py -> multi_model_serving-1.0.0/src/multi_model_serving\n",
      "copying src/multi_model_serving/default_inference_handler.py -> multi_model_serving-1.0.0/src/multi_model_serving\n",
      "copying src/multi_model_serving/encoder.py -> multi_model_serving-1.0.0/src/multi_model_serving\n",
      "copying src/multi_model_serving/handler_service.py -> multi_model_serving-1.0.0/src/multi_model_serving\n",
      "copying src/multi_model_serving/xgb_content_types.py -> multi_model_serving-1.0.0/src/multi_model_serving\n",
      "copying src/multi_model_serving.egg-info/PKG-INFO -> multi_model_serving-1.0.0/src/multi_model_serving.egg-info\n",
      "copying src/multi_model_serving.egg-info/SOURCES.txt -> multi_model_serving-1.0.0/src/multi_model_serving.egg-info\n",
      "copying src/multi_model_serving.egg-info/dependency_links.txt -> multi_model_serving-1.0.0/src/multi_model_serving.egg-info\n",
      "copying src/multi_model_serving.egg-info/top_level.txt -> multi_model_serving-1.0.0/src/multi_model_serving.egg-info\n",
      "Writing multi_model_serving-1.0.0/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'multi_model_serving-1.0.0' (and everything under it)\n",
      "Sending build context to Docker daemon  9.728kB\n",
      "Step 1/15 : FROM tensorflow/tensorflow:latest\n",
      " ---> 1d932048a281\n",
      "Step 2/15 : LABEL maintainer=\"Oleg Grytsynevych\"\n",
      " ---> Running in f68f2493ecd6\n",
      "Removing intermediate container f68f2493ecd6\n",
      " ---> 7a617435d0e3\n",
      "Step 3/15 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=true\n",
      " ---> Running in 8bd288016f57\n",
      "Removing intermediate container 8bd288016f57\n",
      " ---> 9704c867de47\n",
      "Step 4/15 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Running in 9d631e2b5718\n",
      "Removing intermediate container 9d631e2b5718\n",
      " ---> ce02a040b2f7\n",
      "Step 5/15 : RUN apt-get update &&     apt-get -y install         build-essential         libatlas-base-dev          git         wget         curl         openjdk-8-jdk-headless\n",
      " ---> Running in 3fc843192116\n",
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1418 kB]\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [473 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2221 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [506 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.5 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2188 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2658 kB]\n",
      "Fetched 9750 kB in 1s (6783 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "build-essential is already the newest version (12.4ubuntu1).\n",
      "build-essential set to manually installed.\n",
      "curl is already the newest version (7.58.0-2ubuntu3.13).\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java fontconfig-config fonts-dejavu-core git-man java-common\n",
      "  less libatlas3-base libavahi-client3 libavahi-common-data libavahi-common3\n",
      "  libbsd0 libcups2 libcurl3-gnutls libedit2 liberror-perl libfontconfig1\n",
      "  libfreetype6 libgfortran4 libjpeg-turbo8 libjpeg8 liblcms2-2 libnspr4\n",
      "  libnss3 libpcsclite1 libpng16-16 libssl1.0.0 libx11-6 libx11-data libxau6\n",
      "  libxcb1 libxdmcp6 libxext6 libxi6 libxmuu1 libxrender1 libxtst6\n",
      "  multiarch-support openjdk-8-jre-headless openssh-client ucf x11-common xauth\n",
      "Suggested packages:\n",
      "  gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-el git-email\n",
      "  git-gui gitk gitweb git-cvs git-mediawiki git-svn default-jre libatlas-doc\n",
      "  liblapack-doc cups-common liblcms2-utils pcscd openjdk-8-demo\n",
      "  openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-ipafont-gothic\n",
      "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
      "  keychain libpam-ssh monkeysphere ssh-askpass\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java fontconfig-config fonts-dejavu-core git git-man\n",
      "  java-common less libatlas-base-dev libatlas3-base libavahi-client3\n",
      "  libavahi-common-data libavahi-common3 libbsd0 libcups2 libcurl3-gnutls\n",
      "  libedit2 liberror-perl libfontconfig1 libfreetype6 libgfortran4\n",
      "  libjpeg-turbo8 libjpeg8 liblcms2-2 libnspr4 libnss3 libpcsclite1 libpng16-16\n",
      "  libssl1.0.0 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxext6 libxi6\n",
      "  libxmuu1 libxrender1 libxtst6 multiarch-support openjdk-8-jdk-headless\n",
      "  openjdk-8-jre-headless openssh-client ucf wget x11-common xauth\n",
      "0 upgraded, 46 newly installed, 0 to remove and 16 not upgraded.\n",
      "Need to get 56.6 MB of archives.\n",
      "After this operation, 252 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 multiarch-support amd64 2.27-3ubuntu1.4 [6944 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxau6 amd64 1:1.0.8-1ubuntu1 [7556 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbsd0 amd64 0.8.7-1ubuntu0.1 [41.6 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxdmcp6 amd64 1:1.1.2-3 [10.7 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb1 amd64 1.13-2~ubuntu18.04 [45.5 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-data all 2:1.6.4-3ubuntu0.4 [114 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-6 amd64 2:1.6.4-3ubuntu0.4 [572 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxext6 amd64 2:1.3.3-1 [29.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libjpeg-turbo8 amd64 1.5.2-0ubuntu5.18.04.4 [110 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 less amd64 487-0.1 [112 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 ucf all 3.0038 [50.5 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libedit2 amd64 3.1-20170329-1 [76.9 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpng16-16 amd64 1.6.34-1ubuntu0.18.04.2 [176 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssl1.0.0 amd64 1.0.2n-1ubuntu5.6 [1089 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmuu1 amd64 2:1.1.2-2 [9674 B]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssh-client amd64 1:7.6p1-4ubuntu0.3 [614 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 wget amd64 1.19.4-1ubuntu2.2 [316 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 xauth amd64 1:1.0.10-1 [24.6 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 java-common all 0.68ubuntu1~18.04.1 [14.5 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libavahi-common-data amd64 0.7-3.1ubuntu1.3 [22.2 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libavahi-common3 amd64 0.7-3.1ubuntu1.3 [21.6 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libavahi-client3 amd64 0.7-3.1ubuntu1.3 [25.2 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcups2 amd64 2.2.7-1ubuntu2.8 [211 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 liblcms2-2 amd64 2.9-1ubuntu0.1 [139 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjpeg8 amd64 8c-2ubuntu8 [2194 B]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libfreetype6 amd64 2.8.1-2ubuntu2.1 [335 kB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1041 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig-config all 2.12.6-0ubuntu2 [55.8 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfontconfig1 amd64 2.12.6-0ubuntu2 [137 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnspr4 amd64 2:4.18-1ubuntu1 [112 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnss3 amd64 2:3.35-2ubuntu2.12 [1220 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpcsclite1 amd64 1.8.23-1 [21.3 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxi6 amd64 2:1.7.9-1 [29.2 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrender1 amd64 1:0.9.10-1 [18.7 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 x11-common all 1:7.7+19ubuntu7.1 [22.5 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u292-b10-0ubuntu1~18.04 [28.2 MB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ca-certificates-java all 20180516ubuntu1~18.04.1 [12.2 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcurl3-gnutls amd64 7.58.0-2ubuntu3.13 [218 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 liberror-perl all 0.17025-1 [22.8 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 git-man all 1:2.17.1-1ubuntu0.8 [804 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 git amd64 1:2.17.1-1ubuntu0.8 [3916 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgfortran4 amd64 7.5.0-3ubuntu1~18.04 [492 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libatlas3-base amd64 3.10.3-5 [3732 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libatlas-base-dev amd64 3.10.3-5 [4022 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u292-b10-0ubuntu1~18.04 [8284 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 56.6 MB in 3s (18.5 MB/s)\n",
      "Selecting previously unselected package multiarch-support.\n",
      "(Reading database ... 15065 files and directories currently installed.)\n",
      "Preparing to unpack .../0-multiarch-support_2.27-3ubuntu1.4_amd64.deb ...\n",
      "Unpacking multiarch-support (2.27-3ubuntu1.4) ...\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "Preparing to unpack .../1-libxau6_1%3a1.0.8-1ubuntu1_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.8-1ubuntu1) ...\n",
      "Selecting previously unselected package libbsd0:amd64.\n",
      "Preparing to unpack .../2-libbsd0_0.8.7-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libbsd0:amd64 (0.8.7-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../3-libxdmcp6_1%3a1.1.2-3_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../4-libxcb1_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../5-libx11-data_2%3a1.6.4-3ubuntu0.4_all.deb ...\n",
      "Unpacking libx11-data (2:1.6.4-3ubuntu0.4) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../6-libx11-6_2%3a1.6.4-3ubuntu0.4_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.6.4-3ubuntu0.4) ...\n",
      "Setting up multiarch-support (2.27-3ubuntu1.4) ...\n",
      "Selecting previously unselected package libxext6:amd64.\n",
      "(Reading database ... 15355 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libxext6_2%3a1.3.3-1_amd64.deb ...\n",
      "Unpacking libxext6:amd64 (2:1.3.3-1) ...\n",
      "Selecting previously unselected package libjpeg-turbo8:amd64.\n",
      "Preparing to unpack .../01-libjpeg-turbo8_1.5.2-0ubuntu5.18.04.4_amd64.deb ...\n",
      "Unpacking libjpeg-turbo8:amd64 (1.5.2-0ubuntu5.18.04.4) ...\n",
      "Selecting previously unselected package less.\n",
      "Preparing to unpack .../02-less_487-0.1_amd64.deb ...\n",
      "Unpacking less (487-0.1) ...\n",
      "Selecting previously unselected package ucf.\n",
      "Preparing to unpack .../03-ucf_3.0038_all.deb ...\n",
      "Moving old data out of the way\n",
      "Unpacking ucf (3.0038) ...\n",
      "Selecting previously unselected package libedit2:amd64.\n",
      "Preparing to unpack .../04-libedit2_3.1-20170329-1_amd64.deb ...\n",
      "Unpacking libedit2:amd64 (3.1-20170329-1) ...\n",
      "Selecting previously unselected package libpng16-16:amd64.\n",
      "Preparing to unpack .../05-libpng16-16_1.6.34-1ubuntu0.18.04.2_amd64.deb ...\n",
      "Unpacking libpng16-16:amd64 (1.6.34-1ubuntu0.18.04.2) ...\n",
      "Selecting previously unselected package libssl1.0.0:amd64.\n",
      "Preparing to unpack .../06-libssl1.0.0_1.0.2n-1ubuntu5.6_amd64.deb ...\n",
      "Unpacking libssl1.0.0:amd64 (1.0.2n-1ubuntu5.6) ...\n",
      "Selecting previously unselected package libxmuu1:amd64.\n",
      "Preparing to unpack .../07-libxmuu1_2%3a1.1.2-2_amd64.deb ...\n",
      "Unpacking libxmuu1:amd64 (2:1.1.2-2) ...\n",
      "Selecting previously unselected package openssh-client.\n",
      "Preparing to unpack .../08-openssh-client_1%3a7.6p1-4ubuntu0.3_amd64.deb ...\n",
      "Unpacking openssh-client (1:7.6p1-4ubuntu0.3) ...\n",
      "Selecting previously unselected package wget.\n",
      "Preparing to unpack .../09-wget_1.19.4-1ubuntu2.2_amd64.deb ...\n",
      "Unpacking wget (1.19.4-1ubuntu2.2) ...\n",
      "Selecting previously unselected package xauth.\n",
      "Preparing to unpack .../10-xauth_1%3a1.0.10-1_amd64.deb ...\n",
      "Unpacking xauth (1:1.0.10-1) ...\n",
      "Selecting previously unselected package java-common.\n",
      "Preparing to unpack .../11-java-common_0.68ubuntu1~18.04.1_all.deb ...\n",
      "Unpacking java-common (0.68ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libavahi-common-data:amd64.\n",
      "Preparing to unpack .../12-libavahi-common-data_0.7-3.1ubuntu1.3_amd64.deb ...\n",
      "Unpacking libavahi-common-data:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Selecting previously unselected package libavahi-common3:amd64.\n",
      "Preparing to unpack .../13-libavahi-common3_0.7-3.1ubuntu1.3_amd64.deb ...\n",
      "Unpacking libavahi-common3:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Selecting previously unselected package libavahi-client3:amd64.\n",
      "Preparing to unpack .../14-libavahi-client3_0.7-3.1ubuntu1.3_amd64.deb ...\n",
      "Unpacking libavahi-client3:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Selecting previously unselected package libcups2:amd64.\n",
      "Preparing to unpack .../15-libcups2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
      "Unpacking libcups2:amd64 (2.2.7-1ubuntu2.8) ...\n",
      "Selecting previously unselected package liblcms2-2:amd64.\n",
      "Preparing to unpack .../16-liblcms2-2_2.9-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking liblcms2-2:amd64 (2.9-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libjpeg8:amd64.\n",
      "Preparing to unpack .../17-libjpeg8_8c-2ubuntu8_amd64.deb ...\n",
      "Unpacking libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../18-libfreetype6_2.8.1-2ubuntu2.1_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.8.1-2ubuntu2.1) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../19-fonts-dejavu-core_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../20-fontconfig-config_2.12.6-0ubuntu2_all.deb ...\n",
      "Unpacking fontconfig-config (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../21-libfontconfig1_2.12.6-0ubuntu2_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../22-libnspr4_2%3a4.18-1ubuntu1_amd64.deb ...\n",
      "Unpacking libnspr4:amd64 (2:4.18-1ubuntu1) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../23-libnss3_2%3a3.35-2ubuntu2.12_amd64.deb ...\n",
      "Unpacking libnss3:amd64 (2:3.35-2ubuntu2.12) ...\n",
      "Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../24-libpcsclite1_1.8.23-1_amd64.deb ...\n",
      "Unpacking libpcsclite1:amd64 (1.8.23-1) ...\n",
      "Selecting previously unselected package libxi6:amd64.\n",
      "Preparing to unpack .../25-libxi6_2%3a1.7.9-1_amd64.deb ...\n",
      "Unpacking libxi6:amd64 (2:1.7.9-1) ...\n",
      "Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../26-libxrender1_1%3a0.9.10-1_amd64.deb ...\n",
      "Unpacking libxrender1:amd64 (1:0.9.10-1) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package x11-common.\n",
      "Preparing to unpack .../27-x11-common_1%3a7.7+19ubuntu7.1_all.deb ...\n",
      "dpkg-query: no packages found matching nux-tools\n",
      "Unpacking x11-common (1:7.7+19ubuntu7.1) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../28-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
      "Preparing to unpack .../29-openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "Preparing to unpack .../30-ca-certificates-java_20180516ubuntu1~18.04.1_all.deb ...\n",
      "Unpacking ca-certificates-java (20180516ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libcurl3-gnutls:amd64.\n",
      "Preparing to unpack .../31-libcurl3-gnutls_7.58.0-2ubuntu3.13_amd64.deb ...\n",
      "Unpacking libcurl3-gnutls:amd64 (7.58.0-2ubuntu3.13) ...\n",
      "Selecting previously unselected package liberror-perl.\n",
      "Preparing to unpack .../32-liberror-perl_0.17025-1_all.deb ...\n",
      "Unpacking liberror-perl (0.17025-1) ...\n",
      "Selecting previously unselected package git-man.\n",
      "Preparing to unpack .../33-git-man_1%3a2.17.1-1ubuntu0.8_all.deb ...\n",
      "Unpacking git-man (1:2.17.1-1ubuntu0.8) ...\n",
      "Selecting previously unselected package git.\n",
      "Preparing to unpack .../34-git_1%3a2.17.1-1ubuntu0.8_amd64.deb ...\n",
      "Unpacking git (1:2.17.1-1ubuntu0.8) ...\n",
      "Selecting previously unselected package libgfortran4:amd64.\n",
      "Preparing to unpack .../35-libgfortran4_7.5.0-3ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\n",
      "Selecting previously unselected package libatlas3-base:amd64.\n",
      "Preparing to unpack .../36-libatlas3-base_3.10.3-5_amd64.deb ...\n",
      "Unpacking libatlas3-base:amd64 (3.10.3-5) ...\n",
      "Selecting previously unselected package libatlas-base-dev:amd64.\n",
      "Preparing to unpack .../37-libatlas-base-dev_3.10.3-5_amd64.deb ...\n",
      "Unpacking libatlas-base-dev:amd64 (3.10.3-5) ...\n",
      "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
      "Preparing to unpack .../38-openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
      "Setting up libedit2:amd64 (3.1-20170329-1) ...\n",
      "Setting up git-man (1:2.17.1-1ubuntu0.8) ...\n",
      "Setting up less (487-0.1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up libssl1.0.0:amd64 (1.0.2n-1ubuntu5.6) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\n",
      "Setting up libpng16-16:amd64 (1.6.34-1ubuntu0.18.04.2) ...\n",
      "Setting up liberror-perl (0.17025-1) ...\n",
      "Setting up liblcms2-2:amd64 (2.9-1ubuntu0.1) ...\n",
      "Setting up libpcsclite1:amd64 (1.8.23-1) ...\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\n",
      "Setting up libcurl3-gnutls:amd64 (7.58.0-2ubuntu3.13) ...\n",
      "Setting up java-common (0.68ubuntu1~18.04.1) ...\n",
      "Setting up libjpeg-turbo8:amd64 (1.5.2-0ubuntu5.18.04.4) ...\n",
      "Setting up libbsd0:amd64 (0.8.7-1ubuntu0.1) ...\n",
      "Setting up libnspr4:amd64 (2:4.18-1ubuntu1) ...\n",
      "Setting up ucf (3.0038) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up libfreetype6:amd64 (2.8.1-2ubuntu2.1) ...\n",
      "Setting up wget (1.19.4-1ubuntu2.2) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Setting up x11-common (1:7.7+19ubuntu7.1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up openssh-client (1:7.6p1-4ubuntu0.3) ...\n",
      "Setting up git (1:2.17.1-1ubuntu0.8) ...\n",
      "Setting up libx11-data (2:1.6.4-3ubuntu0.4) ...\n",
      "Setting up libxau6:amd64 (1:1.0.8-1ubuntu1) ...\n",
      "Setting up libavahi-common-data:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Setting up libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Setting up libatlas3-base:amd64 (3.10.3-5) ...\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3 to provide /usr/lib/x86_64-linux-gnu/libblas.so.3 (libblas.so.3-x86_64-linux-gnu) in auto mode\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3 to provide /usr/lib/x86_64-linux-gnu/liblapack.so.3 (liblapack.so.3-x86_64-linux-gnu) in auto mode\n",
      "Setting up fontconfig-config (2.12.6-0ubuntu2) ...\n",
      "Setting up libnss3:amd64 (2:3.35-2ubuntu2.12) ...\n",
      "Setting up libatlas-base-dev:amd64 (3.10.3-5) ...\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/atlas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/atlas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\n",
      "Setting up libavahi-common3:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Setting up libxcb1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\n",
      "Setting up libx11-6:amd64 (2:1.6.4-3ubuntu0.4) ...\n",
      "Setting up libxmuu1:amd64 (2:1.1.2-2) ...\n",
      "Setting up libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Setting up libavahi-client3:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Setting up libcups2:amd64 (2.2.7-1ubuntu2.8) ...\n",
      "Setting up libxext6:amd64 (2:1.3.3-1) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Setting up xauth (1:1.0.10-1) ...\n",
      "Setting up libxi6:amd64 (2:1.7.9-1) ...\n",
      "Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up ca-certificates-java (20180516ubuntu1~18.04.1) ...\n",
      "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:Certigna_Root_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:Chambers_of_Commerce_Root_-_2008.pem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:Cybertrust_Global_Root.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:DST_Root_CA_X3.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:E-Tugra_Certification_Authority.pem\n",
      "Adding debian:EC-ACC.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:GTS_Root_R1.pem\n",
      "Adding debian:GTS_Root_R2.pem\n",
      "Adding debian:GTS_Root_R3.pem\n",
      "Adding debian:GTS_Root_R4.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority_-_G2.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "Adding debian:Global_Chambersign_Root_-_2008.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_FÅ‘tanÃºsÃ­tvÃ¡ny.pem\n",
      "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:Sonera_Class_2_Root_CA.pem\n",
      "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G3.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:TrustCor_ECA-1.pem\n",
      "Adding debian:TrustCor_RootCert_CA-1.pem\n",
      "Adding debian:TrustCor_RootCert_CA-2.pem\n",
      "Adding debian:Trustis_FPS_Root_CA.pem\n",
      "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
      "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
      "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
      "Adding debian:UCA_Extended_Validation_Root.pem\n",
      "Adding debian:UCA_Global_G2_Root.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:VeriSign_Universal_Root_Certification_Authority.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:certSIGN_Root_CA_G2.pem\n",
      "Adding debian:e-Szigno_Root_CA_2017.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
      "Adding debian:emSign_Root_CA_-_C1.pem\n",
      "Adding debian:emSign_Root_CA_-_G1.pem\n",
      "done.\n",
      "Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing triggers for ca-certificates (20210119~18.04.1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "done.\n",
      "done.\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Removing intermediate container 3fc843192116\n",
      " ---> 95d4f2cec3cb\n",
      "Step 6/15 : ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1 PYTHONIOENCODING=UTF-8 LANG=C.UTF-8 LC_ALL=C.UTF-8\n",
      " ---> Running in 83bd91206e60\n",
      "Removing intermediate container 83bd91206e60\n",
      " ---> b1531e12072b\n",
      "Step 7/15 : RUN mkdir -p /opt/ml/model\n",
      " ---> Running in 3a8045c0c0f1\n",
      "Removing intermediate container 3a8045c0c0f1\n",
      " ---> eb4bd133c323\n",
      "Step 8/15 : RUN pip --no-cache-dir install -U pip\n",
      " ---> Running in c14bd3fd5ef2\n",
      "Collecting pip\n",
      "  Downloading pip-21.1.3-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.4\n",
      "    Uninstalling pip-20.2.4:\n",
      "      Successfully uninstalled pip-20.2.4\n",
      "Successfully installed pip-21.1.3\n",
      "Removing intermediate container c14bd3fd5ef2\n",
      " ---> 404b20b741ca\n",
      "Step 9/15 : RUN pip --no-cache-dir install multi-model-server                                sagemaker-inference                                retrying\n",
      " ---> Running in 970bf7ebe63d\n",
      "Collecting multi-model-server\n",
      "  Downloading multi_model_server-1.1.4-py2.py3-none-any.whl (4.9 MB)\n",
      "Collecting sagemaker-inference\n",
      "  Downloading sagemaker_inference-1.5.6.tar.gz (19 kB)\n",
      "Collecting retrying\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.8.0-cp36-cp36m-manylinux2010_x86_64.whl (291 kB)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-8.3.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "Collecting model-archiver\n",
      "  Downloading model_archiver-1.0.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sagemaker-inference) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sagemaker-inference) (1.15.0)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Building wheels for collected packages: sagemaker-inference, retrying, future\n",
      "  Building wheel for sagemaker-inference (setup.py): started\n",
      "  Building wheel for sagemaker-inference (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-inference: filename=sagemaker_inference-1.5.6-py2.py3-none-any.whl size=27006 sha256=b52f5cf48ef1d59f7aec1598d52e9805b8e01eab92b040e5b59c76648f1db4ab\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nalnsh8v/wheels/a2/da/43/c2da42a0388e208d1aaaec54b68b85a60df2a62e4d2a8c1993\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11421 sha256=5e4e8c779e20f19953ecb5c94a9b307ce53b084bed77ca480f53e807b7fe3741\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nalnsh8v/wheels/ac/cb/8a/b27bf6323e2f4c462dcbf77d70b7c5e7868a7fbe12871770cf\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=62e961a8fd0504322f659da1033b06e09ac882f302ca4aa4394a1d0e32fdedff\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nalnsh8v/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "Successfully built sagemaker-inference retrying future\n",
      "Installing collected packages: future, enum-compat, scipy, retrying, psutil, Pillow, model-archiver, sagemaker-inference, multi-model-server\n",
      "Successfully installed Pillow-8.3.1 enum-compat-0.0.3 future-0.18.2 model-archiver-1.0.3 multi-model-server-1.1.4 psutil-5.8.0 retrying-1.3.3 sagemaker-inference-1.5.6 scipy-1.5.4\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 970bf7ebe63d\n",
      " ---> eb16e9639bf4\n",
      "Step 10/15 : RUN pip --no-cache-dir install mlio\n",
      " ---> Running in 099c0706e2db\n",
      "Collecting mlio\n",
      "  Downloading mlio-0.9.1-py3-none-any.whl (22 kB)\n",
      "Collecting joblib~=0.11\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "Collecting scikit-learn>=0.17\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "Collecting packaging<17,>=16.8\n",
      "  Downloading packaging-16.8-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyparsing\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging<17,>=16.8->mlio) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->mlio) (1.5.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->mlio) (1.19.5)\n",
      "Installing collected packages: threadpoolctl, pyparsing, joblib, scikit-learn, packaging, mlio\n",
      "Successfully installed joblib-0.17.0 mlio-0.9.1 packaging-16.8 pyparsing-2.4.7 scikit-learn-0.24.2 threadpoolctl-2.2.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 099c0706e2db\n",
      " ---> 07f640acf46c\n",
      "Step 11/15 : WORKDIR /\n",
      " ---> Running in d32ab10da606\n",
      "Removing intermediate container d32ab10da606\n",
      " ---> 798cd499c48c\n",
      "Step 12/15 : COPY code/multi_model_serving-1.0.0.tar.gz /multi_model_serving-1.0.0.tar.gz\n",
      " ---> b5b3bc914621\n",
      "Step 13/15 : RUN pip install /multi_model_serving-1.0.0.tar.gz && rm /multi_model_serving-1.0.0.tar.gz\n",
      " ---> Running in a1eb263866d9\n",
      "Processing /multi_model_serving-1.0.0.tar.gz\n",
      "Building wheels for collected packages: multi-model-serving\n",
      "  Building wheel for multi-model-serving (setup.py): started\n",
      "  Building wheel for multi-model-serving (setup.py): finished with status 'done'\n",
      "  Created wheel for multi-model-serving: filename=multi_model_serving-1.0.0-py3-none-any.whl size=5735 sha256=02ec3c24c6da8dd11cb8208ef0337fca318460970fb7d42836ee8d7a603e0f55\n",
      "  Stored in directory: /root/.cache/pip/wheels/2d/aa/39/f055dee95e1415740e88e73ca29d1029a4107090b94d578aff\n",
      "Successfully built multi-model-serving\n",
      "Installing collected packages: multi-model-serving\n",
      "Successfully installed multi-model-serving-1.0.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container a1eb263866d9\n",
      " ---> 2717c0486656\n",
      "Step 14/15 : COPY code/serve.py /serve.py\n",
      " ---> cefb993ab356\n",
      "Step 15/15 : ENTRYPOINT [\"python\", \"serve.py\"]\n",
      " ---> Running in 79926b1948e2\n",
      "Removing intermediate container 79926b1948e2\n",
      " ---> db79fc8b5158\n",
      "Successfully built db79fc8b5158\n",
      "Successfully tagged sagemaker-serving-containers/diffdl-container:latest\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryUri\": \"785577973223.dkr.ecr.us-east-1.amazonaws.com/sagemaker-serving-containers/diffdl-container\", \n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            }, \n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }, \n",
      "            \"registryId\": \"785577973223\", \n",
      "            \"imageTagMutability\": \"MUTABLE\", \n",
      "            \"repositoryArn\": \"arn:aws:ecr:us-east-1:785577973223:repository/sagemaker-serving-containers/diffdl-container\", \n",
      "            \"repositoryName\": \"sagemaker-serving-containers/diffdl-container\", \n",
      "            \"createdAt\": 1626372297.0\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [785577973223.dkr.ecr.us-east-1.amazonaws.com/sagemaker-serving-containers/diffdl-container]\n",
      "\n",
      "\u001b[1B897bce40: Preparing \n",
      "\u001b[1Bdae4b8dd: Preparing \n",
      "\u001b[1B87f9a136: Preparing \n",
      "\u001b[1Bc1070646: Preparing \n",
      "\u001b[1B3f9722a9: Preparing \n",
      "\u001b[1B633053c1: Preparing \n",
      "\u001b[1Bfa7296bc: Preparing \n",
      "\u001b[1B7734672b: Preparing \n",
      "\u001b[1B0c0a3deb: Preparing \n",
      "\u001b[1B1cfe71d6: Preparing \n",
      "\u001b[1Bd69c1c3b: Preparing \n",
      "\u001b[1Bd7a6e6b8: Preparing \n",
      "\u001b[1B828d7364: Preparing \n",
      "\u001b[1Bb79b7c2f: Preparing \n",
      "\u001b[1B763a045a: Preparing \n",
      "\u001b[1Bc6d2db45: Preparing \n",
      "\u001b[1Bbacb0351: Preparing \n",
      "\u001b[15B1070646: Pushing  30.49MB/84.46MB7A\u001b[2K\u001b[17A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[13A\u001b[2K\u001b[15A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[15A\u001b[2K\u001b[17A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[12A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[13A\u001b[2K\u001b[15A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[13A\u001b[2K\u001b[11A\u001b[2K\u001b[13A\u001b[2K\u001b[15A\u001b[2K\u001b[13A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[11A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2K"
     ]
    }
   ],
   "source": [
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deploy with Amazon SageMaker</h2>\n",
    "\n",
    "\n",
    "<h3>Get the container URI</h3>\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to deploy with Amazon SageMaker, which requires the ECR path to the Docker container used for serving as parameter for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785577973223.dkr.ecr.us-east-1.amazonaws.com/sagemaker-serving-containers/diffdl-container:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare two models</h3>\n",
    "\n",
    "We are going to deploy two different XGBoost models to our model server. We will need the serialized models and the inference scripts that we want to use.\n",
    "We will store them in the current notebook folder, under <strong>model_and_code_1/</strong> and <strong>model_and_code_2/</strong>.\n",
    "\n",
    "The purpose of using different models is to show that you can also deploy models that require diverse features and pre/post processing code.\n",
    "\n",
    "First model is a regression model trained on the [Abalone data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html) originally from the [UCI data repository](https://archive.ics.uci.edu/ml/datasets/abalone).\n",
    "For further information, please refer to this [example](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb).\n",
    "\n",
    "Second model is a binary classification model built by following this workshop: https://github.com/aws-samples/amazon-sagemaker-build-train-deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./code/\n",
      "./code/predictor.py\n",
      "./xgboost-model\n",
      "./\n",
      "./code/\n",
      "./code/predictor.py\n",
      "./model.bin\n"
     ]
    }
   ],
   "source": [
    "! rm -rf ./model_and_code_1/.ipynb_checkpoints\n",
    "! rm -rf ./model_and_code_1/code/.ipynb_checkpoints\n",
    "! rm -rf ./model_and_code_2/.ipynb_checkpoints\n",
    "! rm -rf ./model_and_code_2/code/.ipynb_checkpoints\n",
    "\n",
    "! tar -C ./model_and_code_1/ -cvzf model1.tar.gz ./\n",
    "! tar -C ./model_and_code_2/ -cvzf model2.tar.gz ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the custom inference script for the first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpkl\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    model_file = model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/xgboost-model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    model = pkl.load(\u001b[36mopen\u001b[39;49;00m(model_file, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n"
     ]
    }
   ],
   "source": [
    "! pygmentize model_and_code_1/code/predictor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the one for the second model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpkl\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmulti_model_serving\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m encoder \u001b[34mas\u001b[39;49;00m xgb_encoders\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(input_data, content_type):    \n",
      "    \u001b[34mreturn\u001b[39;49;00m xgb_encoders.decode(input_data, content_type)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    model_file = model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/model.bin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    model = pkl.load(\u001b[36mopen\u001b[39;49;00m(model_file, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n"
     ]
    }
   ],
   "source": [
    "! pygmentize model_and_code_2/code/predictor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deploy a single model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 33.5 KiB/33.5 KiB (398.5 KiB/s) with 1 file(s) remaining\r",
      "upload: ./model1.tar.gz to s3://sagemaker-us-east-1-785577973223/diffdl-container/model/model1.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "s3_model_path = 's3://{0}/{1}/model/model1.tar.gz'.format(bucket, prefix)\n",
    "!aws s3 cp model1.tar.gz {s3_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "from sagemaker.model import Model\n",
    "\n",
    "model_name = 'multi-model-server-model-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "model = Model(model_data = s3_model_path,\n",
    "              image_uri = container_image_uri,\n",
    "              env = {\n",
    "                  'SAGEMAKER_PROGRAM': 'predictor'\n",
    "              },\n",
    "              role=role,\n",
    "              name = model_name,\n",
    "              predictor_cls = sagemaker.predictor.Predictor,\n",
    "              #sagemaker_session=sagemaker_session #comment this line for local mode.\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Note:</strong> the environment variable SAGEMAKER_PREDICTOR is used to specify the name of the custom inference script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the image locally `docker run -it --rm 785577973223.dkr.ecr.us-east-1.amazonaws.com/sagemaker-serving-containers/diffdl-container:latest bash`.\n",
    "Inference API bind to: http://0.0.0.0:8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(echo -n '{ INSERT JSON HERE }') | curl -H \"Content-Type: application/json\" -d @- $ENDPOINT_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the short-lived AWS credentials found in session. They might expire while running.\n",
      "Failed to import yaml. Local mode features will be impaired or broken. Please run \"pip install 'sagemaker[local]'\" to install all required dependencies.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-model-server-single-ep-2021-07-15-22-06-47\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ed58b465d7b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mendpoint_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'multi-model-server-single-ep-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d-%H-%M-%S\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m pred = model.deploy(initial_instance_count=1,\n\u001b[0m\u001b[1;32m      4\u001b[0m                     \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'local'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     endpoint_name=endpoint_name)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0mdata_capture_config_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_request_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         self.sagemaker_session.endpoint_from_production_variants(\n\u001b[0m\u001b[1;32m    710\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mproduction_variants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduction_variant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3453\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3454\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2951\u001b[0m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_append_project_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2953\u001b[0;31m         self.sagemaker_client.create_endpoint(\n\u001b[0m\u001b[1;32m   2954\u001b[0m             \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, EndpointName, EndpointConfigName, Tags)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalEndpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         )\n\u001b[0;32m--> 577\u001b[0;31m         self.container.serve(\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ModelDataUrl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Environment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self, model_dir, environment)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0m_pull_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         self._generate_compose_file(\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;34m\"serve\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_env_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_volumes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvolumes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_generate_compose_file\u001b[0;34m(self, command, additional_volumes, additional_env_vars)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_import_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Local mode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0myaml_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_flow_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_generate_compose_file\u001b[0;34m(self, command, additional_volumes, additional_env_vars)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_import_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Local mode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yaml'"
     ]
    }
   ],
   "source": [
    "endpoint_name = 'multi-model-server-single-ep-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "pred = model.deploy(initial_instance_count=1,\n",
    "                    instance_type='local',\n",
    "                    endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "pred.serializer = sagemaker.serializers.CSVSerializer()\n",
    "item = '77,33,143.0,101,212.2,102,104.9,120,15.3,4,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1'\n",
    "pred.predict(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.delete_endpoint()\n",
    "pred.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deploy multiple models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_prefix = 's3://{0}/{1}/modeldata'.format(bucket, prefix)\n",
    "\n",
    "s3_model_1_path = model_data_prefix + '/model1.tar.gz'\n",
    "!aws s3 cp model1.tar.gz {s3_model_1_path}\n",
    "s3_model_2_path = model_data_prefix + '/model2.tar.gz'\n",
    "!aws s3 cp model2.tar.gz {s3_model_2_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from sagemaker.model import Model\n",
    "\n",
    "model_name = 'multi-model-server-multidatamodel-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "model = Model(name = model_name,\n",
    "              model_data = '',\n",
    "              image_uri = container_image_uri,\n",
    "              role=role,\n",
    "              env = {\n",
    "                  'SAGEMAKER_PROGRAM': 'predictor'\n",
    "              },\n",
    "              predictor_cls = sagemaker.predictor.Predictor,\n",
    "              sagemaker_session=sagemaker_session)\n",
    "\n",
    "multi_model = MultiDataModel(name = model_name,\n",
    "                             model_data_prefix = model_data_prefix,\n",
    "                             model = model,\n",
    "                             sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Note:</strong> the environment variable SAGEMAKER_PREDICTOR is used to specify the name of the custom inference script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_endpoint_name = 'multi-model-server-ep-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(multi_endpoint_name)\n",
    "\n",
    "pred = multi_model.deploy(initial_instance_count=1,\n",
    "                          instance_type='ml.m5.xlarge',\n",
    "                          endpoint_name=multi_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Executing inferences</h3>\n",
    "Once the multi-model endpoint is ready, we can invoke either model1 or model2 by changing the target_model variable in the predict() function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "pred = Predictor(multi_endpoint_name)\n",
    "pred.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = '77,33,143.0,101,212.2,102,104.9,120,15.3,4,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1'\n",
    "model_archive = '/model1.tar.gz'\n",
    "pred.predict(item, target_model=model_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = '0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,73.0,79.0,32.0,27.0,45.0,48.0,13.0,62.0'\n",
    "model_archive = '/model2.tar.gz'\n",
    "pred.predict(item, target_model=model_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.delete_endpoint()\n",
    "pred.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
